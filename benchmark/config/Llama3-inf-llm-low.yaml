model:
  type: inf-llm
  path: meta-llama/Meta-Llama-3-8B-Instruct
  block_size: 64
  n_init: 64
  n_local: 512
  topk: 2
  repr_topk: 2
  max_cached_block: 8
  exc_block_size: 512
  fattn: false
  base: 500000
  distance_scale: 1.0
  question_weight: 1.0

max_len: 2147483647
chunk_size: 2048
conv_type: llama-3-inst
