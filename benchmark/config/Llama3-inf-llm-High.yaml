model:
  type: inf-llm
  path: meta-llama/Meta-Llama-3-8B-Instruct
  block_size: 64
  n_init: 128
  n_local: 512
  topk: 8
  repr_topk: 4
  max_cached_block: 32
  exc_block_size: 512
  fattn: false
  base: 500000
  distance_scale: 1.0
  question_weight: 1.0

max_len: 2147483647
chunk_size: 8192
conv_type: llama-3-inst